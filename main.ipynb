{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RDFIA TME 9 : Visualization of Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "plt.rcParams['savefig.dpi'] = 150\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "# Set URL for pretrained model SqueezeNet (Iandola et al (2016))\n",
    "# This is the SqueezeNet network from Iandola et al (2016) trained on ImageNet,\n",
    "# it achieve comparable results to AlexNet on ImageNet while being very compact\n",
    "torchvision.models.vgg.model_urls[\n",
    "    \"squeezenet1_1\"] = \"http://webia.lip6.fr/~douillard/rdfia/squeezenet1_1-f364aa15.pth\"\n",
    "os.environ[\"TORCH_HOME\"] = \"./pytorch_models\"\n",
    "\n",
    "# loading the model\n",
    "model = torchvision.models.squeezenet1_1(pretrained=True)\n",
    "# put in in test mode\n",
    "model.eval()\n",
    "# freeze the paramaters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example images: 25 images from ImageNet\n",
    "f = np.load(\"data/imagenet_val_25.npz\", allow_pickle=True)\n",
    "data, target, class_names = f[\"X\"], f[\"y\"], f[\"label_map\"].item()\n",
    "class_names = {k: v.split(',')[0] for (k, v) in class_names.items()}\n",
    "\n",
    "def show_images(savepath=None):\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    for i in range(24):\n",
    "        plt.subplot(4, 6, i + 1)\n",
    "        plt.imshow(data[i])\n",
    "        plt.title(class_names[target[i]])\n",
    "        plt.axis('off')\n",
    "    plt.gcf().tight_layout()\n",
    "    if savepath: plt.savefig(savepath)\n",
    "    plt.show()\n",
    "\n",
    "show_images(savepath='figures/Images.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saliency_maps import compute_saliency_maps\n",
    "\n",
    "def show_saliency_maps(data, target, model, class_names, savepath=None):\n",
    "    # convert data and target from numpy arrays to Torch Tensors\n",
    "    data_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in data], dim=0)\n",
    "    target_tensor = torch.LongTensor(target)\n",
    "\n",
    "    # compute saliency maps for images in X\n",
    "    saliency = compute_saliency_maps(data_tensor, target_tensor, model)\n",
    "    # convert the saliency map from torch.Tensor to numpy.array and show images\n",
    "    # and saliency maps together.\n",
    "    saliency = saliency.numpy()\n",
    "    N = data.shape[0]\n",
    "    for i in range(N):\n",
    "        plt.subplot(2, N, i + 1)\n",
    "        plt.imshow(data[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[target[i]])\n",
    "        plt.subplot(2, N, N + i + 1)\n",
    "        plt.imshow(saliency[i], cmap=plt.cm.hot)\n",
    "        plt.axis('off')\n",
    "        plt.gcf().set_size_inches(12, 5)\n",
    "    plt.gcf().tight_layout()\n",
    "    if savepath: plt.savefig(savepath)\n",
    "    plt.show()\n",
    "\n",
    "for i in range(5):\n",
    "    show_saliency_maps(data[5*i: 5*i + 5], target[5*i: 5*i + 5], model, class_names,\n",
    "                       savepath='./figures/Saliency-maps_batch{}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fooling images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fooling_examples import make_fooling_image\n",
    "\n",
    "x_tensor = preprocess(Image.fromarray(data[0]))\n",
    "dest_y = 6\n",
    "_ = make_fooling_image(x_tensor, dest_y, model, max_iters=100, confidence=0.99, plot_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fooling_images(data, target, destination_y, model, class_names, savedir=None):\n",
    "\n",
    "    data_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in data], dim=0)\n",
    "    dest_y = destination_y\n",
    "    for idx in range(len(target)):\n",
    "        # prepare tensor data and its fooling version\n",
    "        x_tensor = data_tensor[idx][None]\n",
    "        y = target[idx]\n",
    "        # original prediction score for the class of x\n",
    "        # (not necessarily the predicted label!)\n",
    "        y_score_before = F.softmax(model(x_tensor), 1)[0, y].item()\n",
    "\n",
    "        x_fooling = make_fooling_image(x_tensor, destination_y, model)\n",
    "        # verify the predicted class on the fooling example\n",
    "        scores = model(x_fooling)\n",
    "        dest_y_score, pred_y = map(lambda t: t.item(), F.softmax(scores, 1).max(1))\n",
    "        assert dest_y == pred_y, \"The model is not fooled!\"\n",
    "\n",
    "        # Plots\n",
    "        x_fooling_np = deprocess(x_fooling.clone())\n",
    "        x_fooling_np = np.asarray(x_fooling_np).astype(np.uint8)\n",
    "\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(data[idx])\n",
    "        plt.title(\"Real: {}\\nConfidence: {:.2f}%\".format(class_names[y], y_score_before*100))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(x_fooling_np)\n",
    "        plt.title(\"Fooled: {}\\nConfidence: {:.2f}%\".format(class_names[dest_y], dest_y_score*100))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 3)\n",
    "        x_pre = preprocess(Image.fromarray(data[idx]))\n",
    "        diff = np.asarray(deprocess(x_fooling - x_pre, should_rescale=False))\n",
    "        plt.imshow(diff)\n",
    "        plt.title('Difference')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        diff = np.asarray(deprocess(10 * (x_fooling - x_pre), should_rescale=False))\n",
    "        plt.imshow(diff)\n",
    "        plt.title('Magnified difference (10x)')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.gcf().set_size_inches(12, 5)\n",
    "        plt.gcf().tight_layout()\n",
    "        if savedir:\n",
    "            plt.savefig(Path(savedir)/'Fooling_{}.jpg'.format(idx))\n",
    "        plt.show()\n",
    "\n",
    "show_fooling_images(data, target, 6, model, class_names, savedir='./figures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_visualization import create_class_visualization\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # uncomment this to use GPU\n",
    "\n",
    "# target_y = 281 # Tabby cat\n",
    "# target_y = 187 # Yorkshire Terrier\n",
    "target_y = 76 # Tarantula\n",
    "# target_y = 78 # Tick\n",
    "# target_y = 683 # Oboe\n",
    "# target_y = 366 # Gorilla\n",
    "# target_y = 604 # Hourglass\n",
    "# target_y = np.random.randint(1000) # random class\n",
    "\n",
    "init_img = None\n",
    "l2_reg = 1e-2\n",
    "lr =  5\n",
    "num_iterations = 1000\n",
    "blur_every = 10\n",
    "max_jitter = 16\n",
    "show_every = 100\n",
    "out = create_class_visualization(target_y, model, dtype, init_img, l2_reg, lr, num_iterations,\n",
    "                                 blur_every, max_jitter, show_every, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
