{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RDFIA TME 9 : Visualization of Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'viridis'\n",
    "plt.rcParams['savefig.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "# Set URL for pretrained model SqueezeNet (Iandola et al (2016))\n",
    "# This is the SqueezeNet network from Iandola et al (2016) trained on ImageNet,\n",
    "# it achieve comparable results to AlexNet on ImageNet while being very compact\n",
    "torchvision.models.vgg.model_urls[\n",
    "    \"squeezenet1_1\"] = \"http://webia.lip6.fr/~douillard/rdfia/squeezenet1_1-f364aa15.pth\"\n",
    "os.environ[\"TORCH_HOME\"] = \"./pytorch_models\"\n",
    "\n",
    "# loading the model\n",
    "model = torchvision.models.squeezenet1_1(pretrained=True)\n",
    "# put in in test mode\n",
    "model.eval()\n",
    "# freeze the paramaters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example images: 25 images from ImageNet\n",
    "f = np.load(\"data/imagenet_val_25.npz\", allow_pickle=True)\n",
    "data, target, class_names = f[\"X\"], f[\"y\"], f[\"label_map\"].item()\n",
    "class_names = {k: v.split(',')[0] for (k, v) in class_names.items()}\n",
    "\n",
    "def show_images(savepath=None):\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    for i in range(24):\n",
    "        plt.subplot(4, 6, i + 1)\n",
    "        plt.imshow(data[i])\n",
    "        plt.title(class_names[target[i]])\n",
    "        plt.axis('off')\n",
    "    plt.gcf().tight_layout()\n",
    "    if savepath: plt.savefig(savepath)\n",
    "    plt.show()\n",
    "\n",
    "show_images(savepath='figures/Images.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from saliency_maps import compute_saliency_maps\n",
    "\n",
    "def show_saliency_maps(data, target, model, class_names, savepath=None):\n",
    "    # convert data and target from numpy arrays to Torch Tensors\n",
    "    data_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in data], dim=0)\n",
    "    target_tensor = torch.LongTensor(target)\n",
    "\n",
    "    # compute saliency maps for images in X\n",
    "    saliency = compute_saliency_maps(data_tensor, target_tensor, model)\n",
    "    # convert the saliency map from torch.Tensor to numpy.array and show images\n",
    "    # and saliency maps together.\n",
    "    saliency = saliency.numpy()\n",
    "    N = data.shape[0]\n",
    "    for i in range(N):\n",
    "        plt.subplot(2, N, i + 1)\n",
    "        plt.imshow(data[i])\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[target[i]])\n",
    "        plt.subplot(2, N, N + i + 1)\n",
    "        plt.imshow(saliency[i], cmap=plt.cm.hot)\n",
    "        plt.axis('off')\n",
    "        plt.gcf().set_size_inches(12, 5)\n",
    "    \n",
    "    plt.gcf().tight_layout()\n",
    "    if savepath: plt.savefig(savepath, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "for i in range(5):\n",
    "    show_saliency_maps(data[5*i: 5*i + 5], target[5*i: 5*i + 5], model, class_names,\n",
    "                       savepath='./figures/saliency-maps/batch_{:02}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fooling images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing the output for the target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fooling_examples import make_fooling_image\n",
    "\n",
    "x_tensor = preprocess(Image.fromarray(data[0]))\n",
    "dest_y = 6\n",
    "x_foooled, t = make_fooling_image(x_tensor, dest_y, model, max_iters=100, confidence=0.99, plot_progress=True)\n",
    "print('Number of iterations:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fooling_images(data, target, destination_y, model, class_names, optimization='class_output', savedir=None):\n",
    "\n",
    "    data_tensor = torch.cat([preprocess(Image.fromarray(x)) for x in data], dim=0)\n",
    "    dest_y = destination_y\n",
    "    for idx in range(0, len(target)):\n",
    "        # prepare tensor data and its fooling version\n",
    "        x_tensor = data_tensor[idx][None]\n",
    "        y = target[idx]\n",
    "        # original prediction score for the class of x\n",
    "        # (not necessarily the predicted label!)\n",
    "        y_score_before = F.softmax(model(x_tensor), 1)[0, y].item()\n",
    "\n",
    "        x_fooling, t = make_fooling_image(x_tensor, destination_y, model, max_iters=100, optimization=optimization)\n",
    "        # verify the predicted class on the fooling example\n",
    "        scores = model(x_fooling)\n",
    "        dest_y_score, pred_y = map(lambda t: t.item(), F.softmax(scores, 1).max(1))\n",
    "        success = (dest_y == pred_y)\n",
    "        \n",
    "        # Plots\n",
    "        x_fooling_np = deprocess(x_fooling.clone())\n",
    "        x_fooling_np = np.asarray(x_fooling_np).astype(np.uint8)\n",
    "\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(data[idx])\n",
    "        plt.title(\"Real: {}\\nConfidence: {:.2%}\".format(class_names[y], y_score_before))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(x_fooling_np)\n",
    "        plt.title(\"{}: {}\\n{} \\n{} iterations\"\n",
    "                  .format('Fooling' if success else 'Failed to fool', class_names[dest_y],\n",
    "                          'Confidence: {:.2%}'.format(dest_y_score) if success else '', t))\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 3)\n",
    "        x_pre = preprocess(Image.fromarray(data[idx]))\n",
    "        diff = np.asarray(deprocess(x_fooling - x_pre, should_rescale=False))\n",
    "        plt.imshow(diff)\n",
    "        plt.title('Difference')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        diff = np.asarray(deprocess(10 * (x_fooling - x_pre), should_rescale=False))\n",
    "        plt.imshow(diff)\n",
    "        plt.title('Magnified difference (10x)')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.gcf().set_size_inches(12, 5)\n",
    "        plt.gcf().tight_layout()\n",
    "        if savedir:\n",
    "            plt.savefig(Path(savedir)/'{:02}_{}.jpg'.format(idx, class_names[y]), bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "savedir = \"./figures/fooling-examples/optimization='class_output'\"\n",
    "show_fooling_images(data, target, 6, model, class_names, optimization='class_output', savedir=savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing several ImageNet classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected classes\n",
    "from class_visualization import create_class_visualization\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # uncomment this to use GPU\n",
    "\n",
    "target_selection  = [  8,    # Hen\n",
    "                     281,  # Tabby cat\n",
    "                     187,  # Yorkshire Terrier\n",
    "                      76,   # Tarantula\n",
    "                      78,   # Tick\n",
    "                     683,  # Oboe\n",
    "                     366,  # Gorilla\n",
    "                     604,  # Hourglass\n",
    "                     130,  # Flamingo\n",
    "                   ]\n",
    "# start with given arbitrary parameters\n",
    "# args = dict(\n",
    "#     init_img = None,\n",
    "#     l2_reg = 1e-3,\n",
    "#     learning_rate =  5,\n",
    "#     num_iterations = 200,\n",
    "#     blur_every = 10,\n",
    "#     blur_width = 0.5,\n",
    "#     max_jitter = 16,\n",
    "#     clamp=True,\n",
    "#     show_every = 25)\n",
    "args = dict(\n",
    "    init_img = None,\n",
    "    l2_reg = 1e-4,\n",
    "    learning_rate =  5.0,\n",
    "    num_iterations = 200,\n",
    "    blur_every = 10,\n",
    "    blur_width = 0.5,\n",
    "    max_jitter = 16,\n",
    "    clamp=True,\n",
    "    show_every = 25)\n",
    "\n",
    "ignore_keys = {'show_every', 'class_names'}\n",
    "# get hyperparameters with values in a dict\n",
    "hparams = {key.replace('_','-'): val for key, val in args.items() if key not in ignore_keys}\n",
    "# generate a name for the experiment\n",
    "expe_name = '_'.join(f\"{key}={val}\" for key, val in hparams.items())\n",
    "\n",
    "print('Experiment name:', expe_name)\n",
    "(Path('./figures/class-visualizations/')/expe_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class_images = []  # put all images in a list for plotting them together\n",
    "for target_y in target_selection:\n",
    "    class_name = class_names[target_y]\n",
    "    savepath = './figures/class-visualizations/{}/{}.jpg' .format(expe_name, class_name)\n",
    "    out = create_class_visualization(target_y, model, dtype, **args, class_name=class_name, savepath=savepath)\n",
    "    class_images.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the generated PIL images into a file\n",
    "# import pickle\n",
    "# savepath = Path('./data/class-visualizations/')/expe_name\n",
    "# savepath.mkdir(parents=True, exist_ok=True)\n",
    "# with open(savepath/'images.pkl', 'wb') as fp:\n",
    "#     pickle.dump(class_images, fp)\n",
    "\n",
    "# # with open(savepath/'images.pkl', 'rb') as fp:\n",
    "# #     class_images = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, target, class_names, savepath=None, cols=3, figsize=(10, 10)):\n",
    "    \"\"\"Show a list of images in a grid layout.\"\"\"\n",
    "    rows = math.ceil(len(images) / cols)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        class_name = class_names[target[i]]\n",
    "        plt.title(class_name)\n",
    "        plt.axis('off')\n",
    "    plt.gcf().tight_layout()\n",
    "\n",
    "    if savepath: plt.savefig(savepath, bbox_inches='tight')   \n",
    "    plt.show()\n",
    "\n",
    "savepath = './figures/class-visualizations/{}/Images.jpg' .format(expe_name)\n",
    "show_images(class_images, target_selection, class_names, savepath=savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varing the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected classes\n",
    "target_y = 130 # Flamingo\n",
    "\n",
    "# start with given arbitrary parameters\n",
    "args = dict(\n",
    "    init_img = None,\n",
    "    l2_reg = 1e-3,\n",
    "    learning_rate =  5,\n",
    "    blur_every = 10,\n",
    "    blur_width = 0.5,\n",
    "    max_jitter = 16,\n",
    "    clamp=True)\n",
    "\n",
    "ignore_keys = {'show_every', 'class_names'}\n",
    "# get hyperparameters with values in a dict\n",
    "hparams = {key.replace('_','-'): val for key, val in args.items() if key not in ignore_keys}\n",
    "# generate a name for the experiment\n",
    "expe_name = '_'.join(f\"{key}={val}\" for key, val in hparams.items())\n",
    "\n",
    "print('Experiment name:', expe_name)\n",
    "savedir = Path('./figures/class-visualizations/')/expe_name\n",
    "savedir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "num_iterations_values = [50, 100, 150, 200, 300, 400, 600, 800]\n",
    "class_images = []\n",
    "for num_iterations in num_iterations_values:\n",
    "    args.update(num_iterations = num_iterations,\n",
    "                show_every = num_iterations)\n",
    "    \n",
    "    print('Num iterations:', num_iterations)\n",
    "    class_name = class_names[target_y]\n",
    "    savepath = savedir/'{}__num_iterations={}.jpg'.format(class_name, num_iterations)\n",
    "    out = create_class_visualization(target_y, model, dtype, **args, class_name=class_name, savepath=savepath)\n",
    "    class_images.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, class_name, savepath=None, cols=4, figsize=(12, 7.2)):\n",
    "    \"\"\"Show a list of images in a grid layout.\"\"\"\n",
    "    rows = math.ceil(len(images) / cols)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, num_iterations in zip(range(len(images)), num_iterations_values):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(\"{} \\nNum iterations: {}\".format(class_name, num_iterations))\n",
    "        plt.axis('off')\n",
    "    plt.gcf().tight_layout()\n",
    "\n",
    "    if savepath: plt.savefig(savepath, bbox_inches='tight')   \n",
    "    plt.show()\n",
    "\n",
    "print(savepath)\n",
    "savepath = savedir/'{}__images.jpg'.format(class_name)\n",
    "show_images(class_images, class_name, savepath=savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying the L2 reg. coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected classes\n",
    "target_y = 130 # Flamingo\n",
    "\n",
    "# start with given arbitrary parameters\n",
    "args = dict(\n",
    "    init_img = None,\n",
    "    learning_rate =  5,\n",
    "    num_iterations = 200,\n",
    "    blur_every = 10,\n",
    "    blur_width = 0.5,\n",
    "    max_jitter = 16,\n",
    "    clamp=True,\n",
    "    show_every = 200)\n",
    "  \n",
    "ignore_keys = {'show_every', 'class_names'}\n",
    "# get hyperparameters with values in a dict\n",
    "hparams = {key.replace('_','-'): val for key, val in args.items() if key not in ignore_keys}\n",
    "# generate a name for the experiment\n",
    "expe_name = '_'.join(f\"{key}={val}\" for key, val in hparams.items())\n",
    "\n",
    "print('Experiment name:', expe_name)\n",
    "savedir = Path('./figures/class-visualizations/')/expe_name\n",
    "savedir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "l2_reg_values = [0., 1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1.0, 5.0, 10.0]\n",
    "class_images = []\n",
    "for l2_reg in l2_reg_values:\n",
    "    args.update(l2_reg = l2_reg)\n",
    "    print('L2 reg:', l2_reg)\n",
    "    class_name = class_names[target_y]\n",
    "    savepath = savedir/'{}__l2_reg={}.jpg'.format(class_name, l2_reg)\n",
    "    out = create_class_visualization(target_y, model, dtype, **args, class_name=class_name, savepath=savepath)\n",
    "    class_images.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_images(images, class_name, savepath=None, cols=4, figsize=(12, 10.5)):\n",
    "    \"\"\"Show a list of images in a grid layout.\"\"\"\n",
    "    rows = math.ceil(len(images) / cols)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i, l2_reg in zip(range(len(images)), l2_reg_values):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(\"{} \\nL2 coefficient: {}\".format(class_name, l2_reg))\n",
    "        plt.axis('off')\n",
    "    plt.gcf().tight_layout()\n",
    "    \n",
    "    if savepath: plt.savefig(savepath, bbox_inches='tight')   \n",
    "    plt.show()\n",
    "\n",
    "savepath = savedir/'{}__images.jpg'.format(class_name)\n",
    "show_images(class_images, class_name, savepath=savepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting from an ImageNet image\n",
    "\n",
    "Here we use the ImageNet images as initial images instead of random images. The target class is set as the label of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args = dict(\n",
    "    init_img = 'sample',\n",
    "    l2_reg = 1e-4,\n",
    "    learning_rate =  1,\n",
    "    num_iterations = 50,\n",
    "    blur_every = 10,\n",
    "    blur_width = 0.5,\n",
    "    max_jitter = 16,\n",
    "    clamp=True,\n",
    "    show_every = 15)\n",
    "\n",
    "ignore_keys = {'show_every'}\n",
    "# get hyperparameters with values in a dict\n",
    "hparams = {key.replace('_','-'): val for key, val in args.items() if key not in ignore_keys}\n",
    "# generate a name for the experiment\n",
    "expe_name = '_'.join(f\"{key}={val}\" for key, val in hparams.items())\n",
    "print('Experiment name:', expe_name)\n",
    "\n",
    "savedir = Path('./figures/class-visualizations/')/expe_name\n",
    "savedir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class_images = []\n",
    "for i in range(len(target)):\n",
    "    target_y = target[i]\n",
    "    init_img = torch.Tensor(preprocess(Image.fromarray(data[i])))\n",
    "    class_name = class_names[target_y]\n",
    "\n",
    "    args.update(init_img=init_img)\n",
    "    savepath = savedir/'{:02}_{}'.format(idx, class_name)\n",
    "    out = create_class_visualization(target_y, model, dtype, **args, class_name=class_name, savepath=savepath)\n",
    "    class_images.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "images_selection, target_selection = \\\n",
    "    list(zip(*[(class_images[i], target[i]) for i in [3, 11, 13, 24]]))\n",
    "\n",
    "\n",
    "def show_images(images, target, class_names, savepath=None, cols=4, figsize=(10, 4)):\n",
    "    \"\"\"Show a list of images in a grid layout.\"\"\"\n",
    "    rows = math.ceil(len(images) / cols)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        class_name = class_names[target[i]]\n",
    "        plt.title(class_name)\n",
    "        plt.axis('off')\n",
    "    plt.gcf().tight_layout()\n",
    "\n",
    "    if savepath: plt.savefig(savepath, bbox_inches='tight')   \n",
    "    plt.show()\n",
    "\n",
    "savepath = './figures/class-visualizations/{}/Images.jpg' .format(expe_name)\n",
    "show_images(images_selection, target_selection, class_names, savepath=savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
